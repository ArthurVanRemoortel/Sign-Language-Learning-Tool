{% extends 'sign_language_app/base.html'%}
{% load static %}

{% block title %}
    Exercise
{% endblock %}

{% block content %}
    <div class="container is-max-desktop mt-2">
        <div class="level">
            <button class="delete is-large" id="cancelUnitButton"></button>
            <progress id="unitProgressBar" class="progress is-success ml-5" value="0" max="100"></progress>
        </div>
        <br>
        <br>

        <h1 id="gestureLabel" class="title is-1 has-text-centered ml11">
            <span class="text-wrapper">
            <span class="line line1"></span>
            <span class="letters"></span>
          </span>
        </h1>

        <div class="level">
            <div class="level-item has-text-centered" id="hintsSection">

            </div>
        </div>

        <div class="level camera-box" id="cameraAreaBox">
            <div class="level-item has-text-centered mt-6" id="cameraLoader">
                <div class="loader-1"></div>
            </div>
            <video class="input_video" hidden></video>
            <canvas class="output_canvas camera-canvas" width="1920px" height="1080px" style="width:100%;border-radius:6px">

            </canvas>
        </div>

    </div>
{% endblock %}


{% block javascript %}
    <script defer
    data-gestures="{{ gestures }}"
    >
        const data = document.currentScript.dataset;
        const gestures = JSON.parse(data.gestures);
        const videoElement = document.getElementsByClassName('input_video')[0];
        const canvasElement = document.getElementsByClassName('output_canvas')[0];
        const cameraAreaBox = document.getElementById('cameraAreaBox');
        const cameraLoader = document.getElementById('cameraLoader');
        const unitProgressBar = document.getElementById('unitProgressBar')
        const gestureLabel = document.getElementById('gestureLabel')
        const cancelUnitButton = document.getElementById('cancelUnitButton')
        const hintsSection = document.getElementById('hintsSection')
        const canvasCtx = canvasElement.getContext('2d');
        const recordingCutoffDelay = 1000
        const minRecordingSize = 1000

        let gestureStart = null
        let gestureEnd = null

        let hand_frames = []
        {#let left_frames = []#}
        {#let right_frames = []#}

        let missingHandsTime = null

        let cameraLoaded = false

        let current_gesture_i = 0
        let current_gesture = null

        unitProgressBar.max = gestures.length
        resetRecording()
        loadCamera()

        cancelUnitButton.addEventListener("click", function() { triggerAnim(false); } )

        function loadGesture() {
            if (current_gesture_i >= gestures.length)
                return
            current_gesture = gestures[current_gesture_i]
            hintsSection.innerHTML = ''

            for (const location_id of current_gesture.fields.locations ){
                let image_path = '{% static 'sign_language_app/images/gesture_locations/1.png' %}'.replace('1.png', `${location_id}.png`)
                let location_figure = `
                <figure class="image is-64x64 ml-2 mr-2 hint-image">
                    <img src=${image_path} class="is-rounded" alt="Body location">
                </figure>`
                $('#hintsSection').append(location_figure)
            }
            animateGestureTitle()
            updateProgressBar()
        }

        function updateProgressBar(){
            unitProgressBar.value = current_gesture_i
        }

        function triggerAnim(correct) {
            if (correct){
                $(cameraAreaBox).addClass('feedback-pulse-correct')
            } else {
                $(cameraAreaBox).addClass('feedback-pulse-incorrect')
            }
        }

        $(cameraAreaBox).on('animationend', function(){
            $(cameraAreaBox).removeClass('feedback-pulse-correct');
            $(cameraAreaBox).removeClass('feedback-pulse-incorrect');
        });

        function veryfiUserInput(data){
            let csrf_token = '{{ csrf_token }}';
            $.ajax({
                url: 'http://localhost:8000/api/test',
                data: JSON.stringify(data),
                headers: {'X-CSRFToken': csrf_token},
                contentType: "application/json",
                dataType: "json",
                processData: false,
                type: 'POST',
                success: function(data) {
                    if (data.correct){
                        triggerAnim(true)
                        current_gesture_i += 1
                        loadGesture()
                    } else {
                        triggerAnim(false)
                    }
                },
                error: function(err) { console.log(err); },
                beforeSend: function (xhr) {
                },
            });
        }

        function animateGestureTitle(){
            var textWrapper = document.querySelector('.ml11 .letters');
            textWrapper.textContent = current_gesture.fields.word
            textWrapper.innerHTML = textWrapper.textContent.replace(/([^\x00-\x80]|\w)/g, "<span class='letter'>$&</span>");
            anime.timeline({loop: false})
                .add({
                    targets: '.ml11 .line',
                    scaleY: [0,1],
                    opacity: [0.5,1],
                    easing: "easeOutExpo",
                    duration: 700
                })
                .add({
                    targets: '.ml11 .line',
                    translateX: [0, document.querySelector('.ml11 .letters').getBoundingClientRect().width + 10],
                    easing: "easeOutExpo",
                    duration: 700,
                    delay: 100
                }).add({
                targets: '.ml11 .letter',
                opacity: [0,1],
                easing: "easeOutExpo",
                duration: 600,
                offset: '-=775',
                delay: (el, i) => 34 * (i+1)
            }).add({
                targets: '.line',
                opacity: 0,
                duration: 1000,
                easing: "easeOutExpo",
                delay: 0
            });
        }

        function beginRecording() {
            console.log("Beginning gesture recording...")
            gestureStart = performance.now()
        }

        function resetRecording(){
            gestureStart = null
            gestureEnd = null
            missingHandsTime = null
            hand_frames = []
        }

        function endRecording() {
            // TODO: Only end recording if no hands were detected for multiple frames.
            if (performance.now() - gestureStart < recordingCutoffDelay + minRecordingSize){
                console.log("This recording was to short. This was probably an accident.")
                resetRecording()
                return
            }
            gestureEnd = performance.now()
            console.log("Ended gesture recording")

            let data = {
                hand_frames: hand_frames,
                gesture_id: current_gesture
            };
            veryfiUserInput(data)
            resetRecording()
        }

        const zip = (a, b) => a.map((k, i) => [k, b[i]]);

        function flip_handedness(string){
            if (string === "Left")
                return "Right"
            return "Left"
        }

        function startExercise(){
            $(cameraLoader).remove()
            loadGesture()
        }

        function onResults(results) {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.translate(canvasElement.width, 0);
            canvasCtx.scale(-1, 1);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
            let found_left_hand = null
            let found_right_hand = null
            if (results.multiHandLandmarks) {
                if (results.multiHandLandmarks.length > 0) {
                    missingHandsTime =  null
                    if (gestureStart == null)
                        beginRecording()
                    const zipped_landmarks = zip(results.multiHandLandmarks, results.multiHandedness);
                    for (const landmarks_handed of zipped_landmarks) {
                        let landmarks = landmarks_handed[0]
                        let handedness = flip_handedness(landmarks_handed[1].label)
                        if (handedness === 'Left'){
                            found_left_hand = landmarks
                        } else if (handedness === "Right"){
                            found_right_hand = landmarks
                        }


                        let color = '#00FF00';
                        if (handedness === "Right")
                            color = '#518dce'
                        else
                            color = '#00FF00'
                        drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS,
                            {color: color, lineWidth: 5});
                        drawLandmarks(canvasCtx, landmarks, {color: '#FF0000', lineWidth: 2});
                    }
                    hand_frames.push([found_left_hand, found_right_hand])
                } else {
                    // No hands detected.
                    if (gestureStart != null) {
                        if (missingHandsTime == null)
                            missingHandsTime = performance.now()
                        if (performance.now() - missingHandsTime >= recordingCutoffDelay)
                            endRecording()
                    }
                }

            } else {
                {#console.log("Nothing detected")#}
            }
            canvasCtx.restore();
        }

        function loadCamera(){
            const hands = new Hands({locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
                }});
            hands.setOptions({
                maxNumHands: 2,
                modelComplexity: 1,
                minDetectionConfidence: 0.8,
                minTrackingConfidence: 0.8
            });
            hands.onResults(onResults);


            const camera = new Camera(videoElement, {
                onFrame: async () => {
                    await hands.send({image: videoElement});
                    if (!cameraLoaded){
                        cameraLoaded = true
                        startExercise()
                    }
                },
                width: 1280,
                height: 720
            });
            camera.start()
        }

    </script>
{% endblock %}